{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "859ac8dd-eb99-4d95-a383-4e2dfdcfaa1f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Mosaic AI Agent Framework: Author and deploy a tool-calling DSPy agent (single turn)\n",
    "\n",
    "This notebook shows how to author an DSPy agent and wrap it using the [`ResponsesAgent`](https://mlflow.org/docs/latest/api_reference/python_api/mlflow.pyfunc.html#mlflow.pyfunc.ResponsesAgent) interface to make it compatible with Mosaic AI. In this notebook you learn to:\n",
    "\n",
    "- Author a tool-calling DSPy agent wrapped with `ResponsesAgent`\n",
    "- Manually test the agent's output\n",
    "- Evaluate the agent using Mosaic AI Agent Evaluation\n",
    "- Log and deploy the agent\n",
    "\n",
    "To learn more about authoring an agent using Mosaic AI Agent Framework, see Databricks documentation ([AWS](https://docs.databricks.com/aws/generative-ai/agent-framework/author-agent) | [Azure](https://learn.microsoft.com/azure/databricks/generative-ai/agent-framework/create-chat-model)).\n",
    "\n",
    "**Please note that the agent we build with this tutorial is single-turn, which means it doesn't pass in conversation history in subsequent LLM calls.**\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Address all `TODO`s in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66837e5c-0d42-4d9c-b483-57b1c503c7d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U -qqqq dspy uv databricks-agents unitycatalog-ai mlflow-skinny[databricks]\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "424dbeed-6f5d-4462-86bf-062be45250c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Define the agent in code\n",
    "Define the agent code in a single cell below. This lets you easily write the agent code to a local Python file, using the `%%writefile` magic command, for subsequent logging and deployment.\n",
    "\n",
    "#### Agent tools\n",
    "This agent code adds the built-in Unity Catalog function `system.ai.python_exec` to the agent.\n",
    "\n",
    "For more examples of tools to add to your agent, see Databricks documentation ([AWS](https://docs.databricks.com/aws/generative-ai/agent-framework/agent-tool) | [Azure](https://learn.microsoft.com/en-us/azure/databricks/generative-ai/agent-framework/agent-tool)), and refer to [DSPy tool guide](https://dspy.ai/learn/programming/tools/) for how to convert your tool to DSPy tools.\n",
    "\n",
    "#### Wrap the DSPy agent using the `ResponsesAgent` interface\n",
    "\n",
    "Databricks recommends using `ResponsesAgent` as it simplifies authoring multi-turn conversational agents using an open source standard. See MLflow's [ResponsesAgent documentation](https://www.mlflow.org/docs/latest/llms/responses-agent-intro/).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62aeecf0-0795-4df5-b021-937ce5fc60f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%writefile agent.py\n",
    "import json\n",
    "import re\n",
    "from typing import Any, Generator\n",
    "from uuid import NAMESPACE_DNS, uuid3, uuid4\n",
    "\n",
    "import mlflow\n",
    "from mlflow.pyfunc import ResponsesAgent\n",
    "from mlflow.types.responses import (\n",
    "    ResponsesAgentRequest,\n",
    "    ResponsesAgentResponse,\n",
    "    ResponsesAgentStreamEvent,\n",
    ")\n",
    "from unitycatalog.ai.core.base import get_uc_function_client\n",
    "import dspy\n",
    "\n",
    "############################################\n",
    "# Define your LLM endpoint and system prompt\n",
    "############################################\n",
    "# TODO: Replace with your model serving endpoint, make sure you include the \"databricks/\" prefix.\n",
    "LLM_ENDPOINT_NAME = \"databricks/databricks-claude-3-7-sonnet\"\n",
    "lm = dspy.LM(LLM_ENDPOINT_NAME, cache=False)\n",
    "\n",
    "###############################################################################\n",
    "## Define tools for your agent, enabling it to retrieve data or take actions\n",
    "## beyond text generation\n",
    "## To create and see usage examples of more tools, see\n",
    "## https://docs.databricks.com/en/generative-ai/agent-framework/agent-tool.html\n",
    "###############################################################################\n",
    "tools = []\n",
    "\n",
    "# You can use UDFs in Unity Catalog as agent tools\n",
    "# Below, we add the `system.ai.python_exec` UDF, which provides\n",
    "# a python code interpreter tool to our agent\n",
    "# You can also add local DSPy tools: https://dspy.ai/learn/programming/tools/\n",
    "uc_client = get_uc_function_client()\n",
    "\n",
    "\n",
    "def execute_python_code(code):\n",
    "    \"\"\"Execute the python code\"\"\"\n",
    "    outputs = uc_client.execute_function(function_name=\"system.ai.python_exec\", parameters={\"code\": f\"{code}\"})\n",
    "    if getattr(outputs, \"error\", None):\n",
    "        tool_result = f\"Encountering error {outputs.error}\"\n",
    "    else:\n",
    "        tool_result = outputs.value\n",
    "    return tool_result\n",
    "\n",
    "# Convert the UDF to a `dspy.Tool`.\n",
    "tools.append(dspy.Tool(execute_python_code))\n",
    "\n",
    "\n",
    "# Create custom tool calling message for streaming purposes.\n",
    "# Please refer to the [DSPy streaming guide](https://dspy.ai/tutorials/streaming/) for more details.\n",
    "class MyStatusMessageProvider(dspy.streaming.StatusMessageProvider):\n",
    "    def tool_start_status_message(self, instance, inputs):\n",
    "        tool_calling_info = {\n",
    "            \"tool_name\": instance.name,\n",
    "            \"tool_args\": inputs[\"kwargs\"],\n",
    "        }\n",
    "        return json.dumps(tool_calling_info)\n",
    "\n",
    "    def tool_end_status_message(self, outputs):\n",
    "        tool_result = {\"tool_result\": outputs.value}\n",
    "        return json.dumps(tool_result)\n",
    "\n",
    "\n",
    "############################################\n",
    "# Define the ResponsesAgent\n",
    "############################################\n",
    "class DSPyResponsesAgent(ResponsesAgent):\n",
    "    def __init__(self, agent: dspy.Module, lm: dspy.LM):\n",
    "        self.agent = agent\n",
    "        self.lm = lm\n",
    "        # Convert the agent to be streaming-compatible.\n",
    "        self._streamified_agent = dspy.streamify(\n",
    "            agent,\n",
    "            status_message_provider=MyStatusMessageProvider(),\n",
    "            stream_listeners=[\n",
    "                dspy.streaming.StreamListener(signature_field_name=\"next_thought\", allow_reuse=True),\n",
    "                dspy.streaming.StreamListener(signature_field_name=\"answer\"),\n",
    "                dspy.streaming.StreamListener(signature_field_name=\"reasoning\"),\n",
    "            ],\n",
    "            async_streaming=False,\n",
    "        )\n",
    "        # Agent internal states.\n",
    "        self._concated_stream_chunks = [[]]\n",
    "        self._last_tool_call_id = None\n",
    "\n",
    "    def _dspy_stream_chunk_to_responses(self, chunk) -> dict[str, Any]:\n",
    "        \"Convert from DSPy streaming chunks to Responses output item dictionaries\"\n",
    "\n",
    "        if isinstance(chunk, dspy.streaming.StatusMessage):\n",
    "            # Extract tool calling information to form the clean streaming chunks.\n",
    "            message_dict = json.loads(chunk.message)\n",
    "            if \"tool_name\" in message_dict:\n",
    "                # Set a new tool call ID when detecting a new tool call.\n",
    "                self._last_tool_call_id = str(uuid4())\n",
    "                return self.create_function_call_item(\n",
    "                    id=str(uuid4()),\n",
    "                    call_id=self._last_tool_call_id,\n",
    "                    name=message_dict[\"tool_name\"],\n",
    "                    arguments=json.dumps(message_dict[\"tool_args\"]),\n",
    "                )\n",
    "            elif \"tool_result\" in message_dict:\n",
    "                # `call_id` in the result chunk has to match the `call_id` from tool invocation chunk.\n",
    "                call_id = self._last_tool_call_id\n",
    "                self._last_tool_call_id = None\n",
    "                return self.create_function_call_output_item(\n",
    "                    call_id=call_id,\n",
    "                    output=message_dict[\"tool_result\"],\n",
    "                )\n",
    "        elif isinstance(chunk, dspy.streaming.StreamResponse):\n",
    "            stream_chunk = self.create_text_delta(\n",
    "                delta=chunk.chunk,\n",
    "                item_id=str(\n",
    "                    uuid3(\n",
    "                        NAMESPACE_DNS,\n",
    "                        f\"{chunk.predict_name}.{chunk.signature_field_name}.stream_count{len(self._concated_stream_chunks)}\",\n",
    "                    )\n",
    "                ),  # Generate a deterministic ID because streaming chunks from the same LM call should be grouped together.\n",
    "            )\n",
    "            self._concated_stream_chunks[-1].append(chunk.chunk)\n",
    "            return stream_chunk\n",
    "        \n",
    "\n",
    "    def predict(self, request: ResponsesAgentRequest) -> ResponsesAgentResponse:\n",
    "        outputs = [event.item for event in self.predict_stream(request) if event.type == \"response.output_item.done\"]\n",
    "        return ResponsesAgentResponse(output=[outputs[-1]])\n",
    "\n",
    "    def predict_stream(\n",
    "        self,\n",
    "        request: ResponsesAgentRequest,\n",
    "    ) -> Generator[ResponsesAgentStreamEvent, None, None]:\n",
    "        last_message = request.input[-1]\n",
    "        if last_message.role != \"user\":\n",
    "            raise ValueError(\"No user question detected!\")\n",
    "        # This is a single-turn agent, we only use the last message which is the latest user message.\n",
    "        question = request.input[-1].content\n",
    "\n",
    "        with dspy.context(lm=self.lm):\n",
    "            output = self._streamified_agent(question=question)\n",
    "            for chunk in output:\n",
    "                converted_chunk = self._dspy_stream_chunk_to_responses(chunk)\n",
    "                if isinstance(chunk, dspy.streaming.StatusMessage):\n",
    "                    yield ResponsesAgentStreamEvent(type=\"response.output_item.done\", item=converted_chunk)\n",
    "                elif isinstance(chunk, dspy.streaming.StreamResponse):\n",
    "                    yield ResponsesAgentStreamEvent(**converted_chunk)\n",
    "                    if chunk.is_last_chunk:\n",
    "                        # The output field is finished, we yield the concatenated message with the same id.\n",
    "                        text = \"\".join(self._concated_stream_chunks[-1])\n",
    "                        self._concated_stream_chunks.append([])\n",
    "                        yield ResponsesAgentStreamEvent(\n",
    "                            type=\"response.output_item.done\",\n",
    "                            item=self.create_text_output_item(\n",
    "                                text=text,\n",
    "                                id=converted_chunk[\"item_id\"],\n",
    "                            ),\n",
    "                        )\n",
    "\n",
    "# Create the agent object, and specify it as the agent object to use when\n",
    "# loading the agent back for inference via mlflow.models.set_model()\n",
    "mlflow.dspy.autolog()\n",
    "# For more context about DSPy signature, please read https://dspy.ai/learn/programming/signatures/.\n",
    "agent = dspy.ReAct(\"question->answer\", tools=tools, max_iters=5)\n",
    "AGENT = DSPyResponsesAgent(agent, lm)\n",
    "mlflow.models.set_model(AGENT)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0de7aebd-daca-40ee-8008-e277f99e57f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Test the agent\n",
    "\n",
    "Interact with the agent to test its output and tool-calling abilities. Since this notebook called `mlflow.dspy.autolog()`, you can view the trace for each step the agent takes.\n",
    "\n",
    "Replace this placeholder input with an appropriate domain-specific example for your agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf131f40-d7d6-44df-8e8f-aff43e458150",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b511817a-e442-47be-990e-b9d8d81c216a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from agent import AGENT\n",
    "\n",
    "result = AGENT.predict({\"input\": [{\"role\": \"user\", \"content\": \"What is 6*7 in Python?\"}]})\n",
    "print(result.model_dump(exclude_none=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc73ad02-4132-4442-945f-4fedac6c2990",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for chunk in AGENT.predict_stream({\"input\": [{\"role\": \"user\", \"content\": \"What is 6*7 in Python?\"}]}):\n",
    "    print(chunk.model_dump(exclude_none=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ade67d93-27ff-433c-965c-c41fa7ccebae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Log the agent as an MLflow model\n",
    "\n",
    "Log the agent as code from the `agent.py` file. See [MLflow - Models from Code](https://mlflow.org/docs/latest/models.html#models-from-code).\n",
    "\n",
    "### Enable automatic authentication for Databricks resources\n",
    "For the most common Databricks resource types, Databricks supports and recommends declaring resource dependencies for the agent upfront during logging. This enables automatic authentication passthrough when you deploy the agent. With automatic authentication passthrough, Databricks automatically provisions, rotates, and manages short-lived credentials to securely access these resource dependencies from within the agent endpoint.\n",
    "\n",
    "To enable automatic authentication, specify the dependent Databricks resources when calling `mlflow.pyfunc.log_model().`\n",
    "\n",
    "  - **TODO**: If your Unity Catalog tool queries a [vector search index](docs link) or leverages [external functions](docs link), you need to include the dependent vector search index and UC connection objects, respectively, as resources. See docs ([AWS](https://docs.databricks.com/generative-ai/agent-framework/log-agent.html#specify-resources-for-automatic-authentication-passthrough) | [Azure](https://learn.microsoft.com/azure/databricks/generative-ai/agent-framework/log-agent#resources)).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b3f9551-73e8-4ef1-9331-731571e1a893",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Determine Databricks resources to specify for automatic auth passthrough at deployment time\n",
    "import mlflow\n",
    "from mlflow.models.resources import DatabricksFunction\n",
    "from pkg_resources import get_distribution\n",
    "\n",
    "resources = [DatabricksFunction(function_name=\"system.ai.python_exec\")]\n",
    "\n",
    "with mlflow.start_run():\n",
    "    logged_agent_info = mlflow.pyfunc.log_model(\n",
    "        name=\"agent\",\n",
    "        python_model=\"agent.py\",\n",
    "        pip_requirements=[\n",
    "            \"unitycatalog-ai\",\n",
    "            f\"dspy=={get_distribution('dspy').version}\",\n",
    "            f\"databricks-connect=={get_distribution('databricks-connect').version}\",\n",
    "        ],\n",
    "        resources=resources,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54c05ed5-7728-4803-af62-74ff1aea600b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Evaluate the agent with Agent Evaluation\n",
    "\n",
    "Use Mosaic AI Agent Evaluation to evalaute the agent's responses based on expected responses and other evaluation criteria. Use the evaluation criteria you specify to guide iterations, using MLflow to track the computed quality metrics.\n",
    "See Databricks documentation ([AWS]((https://docs.databricks.com/aws/generative-ai/agent-evaluation) | [Azure](https://learn.microsoft.com/azure/databricks/generative-ai/agent-evaluation/)).\n",
    "\n",
    "\n",
    "To evaluate your tool calls, add custom metrics. See Databricks documentation ([AWS](https://docs.databricks.com/en/generative-ai/agent-evaluation/custom-metrics.html#evaluating-tool-calls) | [Azure](https://learn.microsoft.com/en-us/azure/databricks/generative-ai/agent-evaluation/custom-metrics#evaluating-tool-calls))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "609499e6-afcb-43c9-8330-8611c4edb6a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.genai.scorers import RelevanceToQuery, RetrievalGroundedness, RetrievalRelevance, Safety\n",
    "\n",
    "eval_dataset = [\n",
    "    {\n",
    "        \"inputs\": {\"input\": [{\"role\": \"user\", \"content\": \"Calculate the 15th Fibonacci number\"}]},\n",
    "        \"expected_response\": \"The 15th Fibonacci number is 610.\",\n",
    "    }\n",
    "]\n",
    "\n",
    "eval_results = mlflow.genai.evaluate(\n",
    "    data=eval_dataset,\n",
    "    predict_fn=lambda input: AGENT.predict({\"input\": input}),\n",
    "    scorers=[RelevanceToQuery(), Safety()],  # add more scorers here if they're applicable\n",
    ")\n",
    "\n",
    "# Review the evaluation results in the MLfLow UI (see console output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f463e1d-aeac-48a9-b6df-a29e4f1e62e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Pre-deployment agent validation\n",
    "Before registering and deploying the agent, perform pre-deployment checks using the [mlflow.models.predict()](https://mlflow.org/docs/latest/python_api/mlflow.models.html#mlflow.models.predict) API. See Databricks documentation ([AWS](https://docs.databricks.com/en/machine-learning/model-serving/model-serving-debug.html#validate-inputs) | [Azure](https://learn.microsoft.com/en-us/azure/databricks/machine-learning/model-serving/model-serving-debug#before-model-deployment-validation-checks))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92627265-a9bf-46d9-8b2f-7aba38d4742f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.models.predict(\n",
    "    model_uri=f\"runs:/{logged_agent_info.run_id}/agent\",\n",
    "    input_data={\"input\": [{\"role\": \"user\", \"content\": \"What is 6*7 in Python?!\"}]},\n",
    "    env_manager=\"uv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c11f6e8-d7d7-4424-8b91-bc8dde0a5089",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Register the model to Unity Catalog\n",
    "\n",
    "Before you deploy the agent, you must register the agent to Unity Catalog.\n",
    "\n",
    "- **TODO** Update the `catalog`, `schema`, and `model_name` below to register the MLflow model to Unity Catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4dd57ac-2e57-44ac-8e20-80bad9268489",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "# TODO: define the catalog, schema, and model name for your UC model\n",
    "catalog = \"\"\n",
    "schema = \"\"\n",
    "model_name = \"\"\n",
    "UC_MODEL_NAME = f\"{catalog}.{schema}.{model_name}\"\n",
    "\n",
    "# register the model to UC\n",
    "uc_registered_model_info = mlflow.register_model(model_uri=logged_agent_info.model_uri, name=UC_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4405f486-994e-4776-b131-71d4636a5e4a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Deploy the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50009a39-e63f-4ca6-9000-6ff828c5eb1e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks import agents\n",
    "\n",
    "agents.deploy(\n",
    "    UC_MODEL_NAME,\n",
    "    uc_registered_model_info.version,\n",
    "    tags={\"endpointSource\": \"docs\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48a50a3b-0a21-423b-bb9a-38b7d90f8c9f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Next steps\n",
    "\n",
    "After your agent is deployed, you can chat with it in AI playground to perform additional checks, share it with SMEs in your organization for feedback, or embed it in a production application. See docs ([AWS](https://docs.databricks.com/en/generative-ai/deploy-agent.html) | [Azure](https://learn.microsoft.com/en-us/azure/databricks/generative-ai/deploy-agent)) for details"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "dspy_agent",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
