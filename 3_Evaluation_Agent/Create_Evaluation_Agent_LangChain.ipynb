{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1cfe23d3-26e4-4905-b370-68aa61c0dee9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Building the Evaluation Agent\n",
    "For full documentation on building AI agents in code, [refer to this doc](https://docs.databricks.com/aws/en/generative-ai/agent-framework/author-agent?language=LangGraph).\n",
    "\n",
    "This notebook is developed on DBR 16.4 ML LTS. At the time of writing, 17.3 ML LTS is having issues with Spark Connect and the default client mode. Tested in 17.2 and this works fine. This is because as of 11-Nov-2025 my region (aws us-west-2) only has serverless runtime 17.2 installed. Running DBR 17.3 causes a runtime mis-match error. Until my serverless plane is updated to 17.3, I have to use a slightly older DB Runtime. This is separate from running a notebook in serverless. This has to do with Databricks Connect in the backend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "59e64d00-791b-4b96-af7e-a20aeef72fd2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Dependencies\n",
    "Creating an agent requires the latest version of MLFlow (>=3.1.3), Python 3.10 or newer (default on serverless) as well as the Databricks agent framework and the langchain AI Bridge. Since ChatAgent has been deprecated, we will need to use OpenAI's `ResponsesAgent` framework for an MLFlow-compliant interface :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c5f2708-ad36-474a-9ebc-763d664ea472",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Use -qqq to show any errors or -qqqq for very quiet\n",
    "%pip install -U -qqq langgraph uv databricks-agents databricks-langchain mlflow-skinny[databricks] \n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a4dd8082-d724-4bdb-830b-7bd6884515a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ResponsesAgent Overview\n",
    "It's important to note that `ResponsesAgent` is a wrapper to seamless interface with a variety of different agents in a common way. This means that we can author agents in Databricks, but have them interface with any platform.\n",
    "<br/>\n",
    "<br/>\n",
    "<img src=\"https://docs.databricks.com/aws/en/assets/images/responses-agent-overview-611d843718bf94974d277a365695043c.svg\" width=1000 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69d0b6bc-dbff-4e1c-8ff4-e05ed85e200c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%writefile -a agent.py\n",
    "from typing import Annotated, Any, Generator, Optional, Sequence, TypedDict, Union\n",
    "\n",
    "import mlflow\n",
    "from databricks_langchain import (\n",
    "    ChatDatabricks,\n",
    "    UCFunctionToolkit,\n",
    "    VectorSearchRetrieverTool,\n",
    "    # DatabricksFunctionClient\n",
    ")\n",
    "from langchain_core.messages import AIMessage, AIMessageChunk, AnyMessage\n",
    "from langchain_core.runnables import RunnableConfig, RunnableLambda\n",
    "from langchain_core.tools import BaseTool\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt.tool_node import ToolNode\n",
    "from mlflow.pyfunc import ResponsesAgent\n",
    "from mlflow.types.responses import (\n",
    "    ResponsesAgentRequest,\n",
    "    ResponsesAgentResponse,\n",
    "    ResponsesAgentStreamEvent,\n",
    "    output_to_responses_items_stream,\n",
    "    to_chat_completions_input,\n",
    ")\n",
    "from unitycatalog.ai.core.databricks import DatabricksFunctionClient\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cde80fbe-ea56-45f7-9ac2-ab7d4d455c9d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Defining the Foundation Model\n",
    "As we build up our agent, we need to define the foundation model we want to back the agent. This handles all of the text en/decoding, routing logic (based on descriptions) and instruction handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c1f6877-4908-468b-93d8-407fd5c2591d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%writefile -a agent.py\n",
    "#Define the endpoint to use for the agent foundation and system prompt\n",
    "LLM_ENDPOINT_NAME = \"databricks-claude-3-7-sonnet\"\n",
    "llm = ChatDatabricks(endpoint=LLM_ENDPOINT_NAME)\n",
    "system_prompt = \"You are a helpful assistant that can run Python code.\" #Give my agent a better description later.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b7c038aa-19e5-45b9-a9ff-d895d1e88bd3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### AI Tools\n",
    "Various tools for agent capabilities can be added here. We're creating a collection of tools defined as `tools[]` that we then append to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93eb975f-a983-4947-9f74-a054cb2169f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%writefile -a agent.py\n",
    "tools = []\n",
    "\n",
    "# You can use UDFs in Unity Catalog as agent tools\n",
    "# Below, we add the `system.ai.python_exec` UDF, which provides\n",
    "# a python code interpreter tool to our agent\n",
    "# You can also add local LangChain python tools. See https://python.langchain.com/docs/concepts/tools\n",
    "\n",
    "# TODO: Add additional tools\n",
    "UC_TOOL_NAMES = [\"system.ai.python_exec\"]\n",
    "client = DatabricksFunctionClient(execution_mode=\"serverless\")\n",
    "uc_toolkit = UCFunctionToolkit(function_names=UC_TOOL_NAMES, client=client)\n",
    "tools.extend(uc_toolkit.tools)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "86b940e7-7576-48ee-af22-031ab1acd636",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Vector Search Tools\n",
    "Vector searches and indexes can be used for context adding RAG capabilities to the agent. Databricks endpoints can be used directly using the VectorSearchRetrieverTool(). Other vectord databases can be added as external MCP endpoints. These are all appended to the `tools[]` collection we defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a8674a6-3ee3-4d81-a596-085aae1fe802",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%writefile -a agent.py\n",
    "#Vector search tools are used for unstructured text tools. Useful for a RAG agent.\n",
    "VECTOR_SEARCH_TOOLS = []\n",
    "\n",
    "# To add vector search retriever tools,\n",
    "# use VectorSearchRetrieverTool and create_tool_info,\n",
    "# then append the result to TOOL_INFOS.\n",
    "# Example:\n",
    "# VECTOR_SEARCH_TOOLS.append(\n",
    "#     VectorSearchRetrieverTool(\n",
    "#         index_name=\"\",\n",
    "#         # filters=\"...\"\n",
    "#     )\n",
    "# )\n",
    "tools.extend(VECTOR_SEARCH_TOOLS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2530a3fd-be8e-483d-8a8b-e9ad97947e33",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Agent State\n",
    "`AgentState()` is an object used to persist the conversation turns of the agent. We pass this object into the conversation chain to keep track of what it's doing for the duration of the session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2597b506-4a85-403b-9429-b36d0d01d9e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%writefile -a agent.py\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[AnyMessage], add_messages]\n",
    "    custom_inputs: Optional[dict[str, Any]]\n",
    "    custom_outputs: Optional[dict[str, Any]]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "06b8a9bc-b2ec-4614-bd3c-668210870eec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Agent Logic\n",
    "This is where we define the actual logic for the agent and handle how the tools are called. We're also defining how the agent deals with conversation turns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c8bc6c5-e4ab-4ad3-a2f3-1da699ec9ff9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%writefile -a agent.py\n",
    "def create_tool_calling_agent(\n",
    "    model: ChatDatabricks,\n",
    "    tools: Union[ToolNode, Sequence[BaseTool]],\n",
    "    system_prompt: Optional[str] = None,\n",
    "):\n",
    "    model = model.bind_tools(tools)\n",
    "\n",
    "    # Define the function that determines which node to go to\n",
    "    def should_continue(state: AgentState):\n",
    "        messages = state[\"messages\"]\n",
    "        last_message = messages[-1]\n",
    "        # If there are function calls, continue. else, end\n",
    "        if isinstance(last_message, AIMessage) and last_message.tool_calls:\n",
    "            return \"continue\"\n",
    "        else:\n",
    "            return \"end\"\n",
    "\n",
    "    if system_prompt:\n",
    "        preprocessor = RunnableLambda(\n",
    "            lambda state: [{\"role\": \"system\", \"content\": system_prompt}] + state[\"messages\"]\n",
    "        )\n",
    "    else:\n",
    "        preprocessor = RunnableLambda(lambda state: state[\"messages\"])\n",
    "    model_runnable = preprocessor | model\n",
    "\n",
    "    def call_model(\n",
    "        state: AgentState,\n",
    "        config: RunnableConfig,\n",
    "    ):\n",
    "        response = model_runnable.invoke(state, config)\n",
    "\n",
    "        return {\"messages\": [response]}\n",
    "\n",
    "    workflow = StateGraph(AgentState)\n",
    "\n",
    "    workflow.add_node(\"agent\", RunnableLambda(call_model))\n",
    "    workflow.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "    workflow.set_entry_point(\"agent\")\n",
    "    workflow.add_conditional_edges(\n",
    "        \"agent\",\n",
    "        should_continue,\n",
    "        {\n",
    "            \"continue\": \"tools\",\n",
    "            \"end\": END,\n",
    "        },\n",
    "    )\n",
    "    workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "    return workflow.compile()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "312fa90e-310b-4348-ae6f-d1018fe313aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### ResponsesAgent (OpenAI) Framework\n",
    "Next, we create a new class we're calling LangGraphResponsesAgent which is a concrete implementation of the ResponsesAgent base class. ResponsesAgent is a definition created by OpenAI that's being used by pretty much every major agent platform now. This is becoming the standard implementation. We're going to be seeing future agent registries being built that require this as a protocol. ResponsesAgent is responsible for handling the conversation from human-to-agent, agent-to-agent and agent-to-human in a standard way.\n",
    "\n",
    "**IMPORTANT!** ResponsesAgent() is still classified as experimental within Databricks - OpenAI is now considering ResponsesAgent() as stable release. Databricks _may_ move to a different implementation later. The specific implementation we're using here comes from MLFlow. If you prefer, you can use OpenAI's native implementation, however the MLFlow version supports the full MLOps lifecycle including conversation tracking for easy detection of hallucination.\n",
    "\n",
    "`predict()` is the boundary conversation to and from the agent. This is either the human-agent or agent-agent interface.\n",
    "`predict_stream()` is the internal conversation and discourse the agent has with itself (reasoning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6a2b009-b0ef-421c-8b11-eba7b55b9cce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%writefile -a agent.py\n",
    "class LangGraphResponsesAgent(ResponsesAgent):\n",
    "    def __init__(self, agent):\n",
    "        self.agent = agent\n",
    "\n",
    "    def predict(self, request: ResponsesAgentRequest) -> ResponsesAgentResponse:\n",
    "        outputs = [\n",
    "            event.item\n",
    "            for event in self.predict_stream(request)\n",
    "            if event.type == \"response.output_item.done\"\n",
    "        ]\n",
    "        return ResponsesAgentResponse(output=outputs, custom_outputs=request.custom_inputs)\n",
    "\n",
    "    def predict_stream(\n",
    "        self,\n",
    "        request: ResponsesAgentRequest,\n",
    "    ) -> Generator[ResponsesAgentStreamEvent, None, None]:\n",
    "        cc_msgs = to_chat_completions_input([i.model_dump() for i in request.input])\n",
    "\n",
    "        for event in self.agent.stream({\"messages\": cc_msgs}, stream_mode=[\"updates\", \"messages\"]):\n",
    "            if event[0] == \"updates\":\n",
    "                for node_data in event[1].values():\n",
    "                    if len(node_data.get(\"messages\", [])) > 0:\n",
    "                        yield from output_to_responses_items_stream(node_data[\"messages\"])\n",
    "            # filter the streamed messages to just the generated text messages\n",
    "            elif event[0] == \"messages\":\n",
    "                try:\n",
    "                    chunk = event[1][0]\n",
    "                    if isinstance(chunk, AIMessageChunk) and (content := chunk.content):\n",
    "                        yield ResponsesAgentStreamEvent(\n",
    "                            **self.create_text_delta(delta=content, item_id=chunk.id),\n",
    "                        )\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed66fdcd-fbd8-4b38-ba1c-0d1f158312d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%writefile -a agent.py\n",
    "mlflow.langchain.autolog()\n",
    "agent = create_tool_calling_agent(llm, tools, system_prompt)\n",
    "AGENT = LangGraphResponsesAgent(agent)\n",
    "mlflow.models.set_model(AGENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f45f8191-2a65-426d-b7b4-f01fb5974dd8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Testing the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3fa875fb-5e72-4e0f-9fea-fd774ebd62c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Restart the python interpreter to flush out any lingering instances of in-memory objects\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd01e08c-59e1-485e-98ec-f694402bc9b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Test the summarizer\n",
    "from agent import AGENT\n",
    "\n",
    "result = AGENT.predict({\"input\": [{\"role\": \"user\", \"content\": \"What is 6*7 in Python?\"}]})\n",
    "print(result.model_dump(exclude_none=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d805b467-ca58-432f-bde7-5131a076f28f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Viewing the Results as Chunks\n",
    "Here we can blow out the response and print each chunk as it's processed by the agent. We can also clearly see how the result is being re-assembled. This is the type of conversation the agent has and we can see it's chain of reasoning to help us debug.\n",
    "\n",
    "**NOTE!** The agent description has a big effect on the results. Often logical errors or fallacies can be remedied by fixing the descriptions and instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "136ce9ad-ad9e-45fa-ac17-5fe652a366f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Test internal conversation turns\n",
    "for chunk in AGENT.predict_stream(\n",
    "    {\"input\": [{\"role\": \"user\", \"content\": \"What is 6*7 in Python?\"}]}\n",
    "):\n",
    "    print(chunk.model_dump(exclude_none=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "11f21ffe-f922-49f8-814f-9ad0bceeb91f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Log the agent as an MLflow model\n",
    "__This is taken straight from the custom agent boilerplate example__\n",
    "\n",
    "Log the agent as code from the `agent.py` file (or whatever you called it in the writefile statements). See [MLflow - Models from Code](https://mlflow.org/docs/latest/models.html#models-from-code).\n",
    "\n",
    "If you are creating multiple agents, each one needs to be logged in MLFlow so it can be used later in a multi-agent setup.\n",
    "\n",
    "### Enable automatic authentication for Databricks resources\n",
    "For the most common Databricks resource types, Databricks supports and recommends declaring resource dependencies for the agent upfront **during logging**. This enables automatic authentication passthrough when you deploy the agent. With automatic authentication passthrough, Databricks automatically provisions, rotates, and manages short-lived credentials to securely access these resource dependencies from within the agent endpoint.\n",
    "\n",
    "To enable automatic authentication, specify the dependent Databricks resources when calling `mlflow.pyfunc.log_model().`\n",
    "\n",
    "  - **TODO**: If your Unity Catalog tool queries a [vector search index](docs link) or leverages [external functions](docs link), you need to include the dependent vector search index and UC connection objects, respectively, as resources. See docs ([AWS](https://docs.databricks.com/generative-ai/agent-framework/log-agent.html#specify-resources-for-automatic-authentication-passthrough) | [Azure](https://learn.microsoft.com/azure/databricks/generative-ai/agent-framework/log-agent#resources))."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Create_Evaluation_Agent_LangChain",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
